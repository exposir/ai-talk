# llm-internals/

> L2 | 父级:
> [notes/CLAUDE.md](../CLAUDE.md)

LLM 内部原理深度解析，涵盖 Transformer 架构、注意力机制、训练优化等核心技术。

## 成员清单

- `README.md`: 模块概述
- `transformer-architecture.md`: Transformer 架构
- `attention-variants.md`: 注意力机制变体
- `positional-encoding.md`: 位置编码
- `pre-training.md`: 预训练
- `fine-tuning.md`: 微调
- `alignment.md`: 对齐技术
- `scaling-laws.md`: 缩放定律
- `long-context.md`: 长上下文
- `mixture-of-experts.md`: MoE 混合专家
- `inference-optimization.md`: 推理优化
- `gpt-series.md`: GPT 系列演进
- `open-source-models.md`: 开源模型
- `essential-papers.md`: 必读论文
- `paper-notes.md`: 论文笔记

[PROTOCOL]: 变更时更新此头部，然后检查 CLAUDE.md
