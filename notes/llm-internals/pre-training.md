# щвДшонч╗Г

хдзшпншиАцибхЮЛчЪДхЯ║чбАшонч╗ГщШ╢цо╡уАВ

---

## ЁЯУЭ члашКВхдзч║▓

### 1. шпншиАх╗║цибчЫоцаЗ

- хЫацЮЬшпншиАх╗║циб (CLM)
- цОйчаБшпншиАх╗║циб (MLM)
- хЙНч╝АшпншиАх╗║циб

### 2. Tokenization

- BPE (Byte Pair Encoding)
- WordPiece
- SentencePiece
- Tiktoken

### 3. шонч╗ГцХ░цНо

- цХ░цНоцЭец║Р (Web, ф╣жч▒Н, ф╗гчаБ)
- цХ░цНоц╕Ец┤Чф╕ОхО╗щЗН
- цХ░цНощЕНцпФ

### 4. шонч╗ГцКАцЬп

- ц╖╖хРИч▓╛х║жшонч╗Г
- цвпх║жч┤пчзп
- хнжф╣ачОЗш░Гх║ж

### 5. хИЖх╕Гх╝Пшонч╗Г

- цХ░цНох╣╢шбМ (DP)
- цибхЮЛх╣╢шбМ (TP, PP)
- ZeRO ф╝ШхМЦ

### 6. шонч╗Гчи│хоЪцАз

- Loss Spike хдДчРЖ
- цвпх║жшгБхЙк
- цЭГщЗНхИЭхзЛхМЦ

---

## ЁЯУЪ хПВшАГш╡ДцЦЩ

- [ ] Language Models are Unsupervised Multitask Learners (GPT-2)
- [ ] Training Compute-Optimal Large Language Models (Chinchilla)
