<!--
- [INPUT]: 依赖 notes/llm-internals/CLAUDE.md 的模块定位与索引
- [OUTPUT]: 输出 Scaling Laws 文档
- [POS]: 位于 notes/llm-internals 模块的 Scaling Laws 笔记
- [PROTOCOL]: 变更时更新此头部，然后检查 CLAUDE.md
-->

# Scaling Laws

大模型规模定律研究。

---

## 📝 章节大纲

### 1. 核心发现

- 损失与计算量的幂律关系
- 损失与参数量的关系
- 损失与数据量的关系

### 2. OpenAI Scaling Laws

- 公式推导
- 实验验证
- 预测能力

### 3. Chinchilla 定律

- 计算最优模型
- 参数与数据的最优比例
- 对 GPT-3 的反思

### 4. 实践意义

- 如何规划训练
- 资源分配策略
- 预算约束下的选择

### 5. 新趋势

- 推理时扩展 (Test-time Scaling)
- Scaling 的极限
- 效率优先的趋势

---

## 📚 参考资料

- [ ] Scaling Laws for Neural Language Models (OpenAI)
- [ ] Training Compute-Optimal Large Language Models (Chinchilla)
