<!--
- [INPUT]: 依赖 notes/llm-internals/CLAUDE.md 的模块定位与索引
- [OUTPUT]: 输出 论文精读笔记 文档
- [POS]: 位于 notes/llm-internals 模块的 论文精读笔记 笔记
- [PROTOCOL]: 变更时更新此头部，然后检查 CLAUDE.md
-->

# 论文精读笔记

重点论文的详细解读与笔记。

---

## 📚 笔记索引

### 基础架构

- [ ] Attention Is All You Need 精读
- [ ] BERT 精读
- [ ] GPT 系列精读

### 规模定律

- [ ] Scaling Laws 精读
- [ ] Chinchilla 精读

### 对齐技术

- [ ] InstructGPT 精读
- [ ] DPO 精读

### 效率优化

- [ ] FlashAttention 精读
- [ ] LoRA 精读

---

## 📝 笔记模板

```markdown
# [论文标题]

## 基本信息

- 作者：
- 机构：
- 年份：
- 链接：

## 核心贡献

1.
2.
3.

## 方法详解

## 实验结果

## 个人思考

## 相关工作
```
